<title>Aime 架构与实现：从 PlanAct 到动态演进</title>
<url>https://bytedance.larkoffice.com/wiki/U4HnwGz32iWgQXkMTGdccrbinEh</url>
<content>
最近更新：2026-01-09

## 引言：从有序到演进，构建更强大的智能体
在人工智能的浪潮之巅，智能体（Agent）正从简单的指令执行者，向能够自主规划、适应环境并解决复杂现实任务的伙伴角色演进。早期的智能体设计，如 Aime 1.0 所采用的 **PlanAct** 框架，通过精密的“规划-执行”模式，将复杂任务拆解给一系列预定义的、各有所长的专家 **Actor**。这种“专家团队”模式在处理具有明确边界的专业任务时表现出色，展现了模块化与专业化的力量。

然而，现实世界的复杂性与不确定性远超预设的脚本。当任务需求跨越多个专业领域、执行路径充满未知“岔路口”、信息在传递过程中层层衰减时，静态的规划与固化的角色分工便会暴露出其根本性的脆弱——僵化的流程无法利用“捷径”，固化的角色难以应对“复合型”难题，而信息孤岛则可能导致“差之毫厘，谬以千里”的决策偏差。

为了突破这些结构性局限，Aime 架构迎来了从 1.0 到 1.5 的核心跃迁，其设计哲学从“构建完美的执行机器”转向“培育自适应的智能系统”。Aime 1.5 的核心是**动态演进**，它引入了 **Dynamic Planner**（动态规划器）与 **Dynamic Actor**（动态执行器）的概念，旨在让智能体在与环境的持续交互中学习、适应并涌现出超越初始设定的能力。

本文旨在全面解构 Aime 的统一架构，不仅阐述其从 1.0 到 1.5 的设计思想演变，更将深入剖析其关键组件、核心机制与实现细节。我们将探讨 Aime 如何通过一个统一的框架，融合静态规划的稳定性与动态演进的灵活性，以应对日益复杂的现实世界挑战。

## Aime 统一架构：融合规划与演进的设计哲学
Aime 的架构设计，是对主流智能体思想的一次综合与升华。它既吸收了 **ReAct** 框架中“思考-行动-观察”的交互循环精髓，也继承了 **Plan-and-Execute** 范式在长时域任务上的结构化优势，更通过多智能体系统（MAS）的理念，实现了能力的专业化与扩展。其最终形态，是一个旨在平衡稳定性与适应性的混合式架构。

### 核心理念：PlanAct 与动态演进的统一
Aime 的架构并非是对 1.0 版本的全盘否定，而是一次深刻的拓展。其核心在于将 **PlanAct** 的结构化思想与 1.5 的**动态演进**能力无缝融合。

- **PlanAct 作为基石**：经典的“规划-执行”分离模式依然是 Aime 解决复杂问题的基础框架。一个中心化的 **Planner** 负责将用户的高层目标分解为一系列可执行的步骤，而 **Execution Engine**（执行引擎）则负责调度执行。这为任务的执行提供了基础的结构与可预测性。

- **动态演进作为灵魂**：Aime 1.5 为这套结构化框架注入了灵魂——**自适应性**。**Dynamic Planner** 不再是一次性生成僵化计划，而是根据每一步的执行反馈动态调整、优化甚至重塑整个任务路径。同时，**ActorFactory** 也不再局限于分发固定的专家角色，而是能够根据当前任务的具体需求，动态组装出具备特定工具、知识和能力的“临时专家”——即 **Dynamic Actor**。

这种设计使得 Aime 既能像经验丰富的项目经理一样，对任务进行宏观拆解与规划，又能像身处一线的敏捷团队一样，根据战场的瞬息万变灵活调整战术。

### 三大支柱：Planner、Actor 与上下文
Aime 架构的稳定运行依赖于三大核心支柱的协同作用：

1. **规划与重新规划（Plan & Replan）**：**Planner** 不仅是任务的启动者，更是贯穿始终的导航员。它负责初步规划，并在执行过程中基于 **Actor** 的反馈（成功、失败、意外发现）触发**重新规划（Replan）**机制。这种持续的“规划-执行-评估-再规划”循环，是 Aime 适应不确定性的关键。

2. **专业化与动态化执行（Actor & ActorFactory）**：执行层由一系列 **Actor** 构成。在 1.0 时代，这些是预定义的专家，如精通代码的 **Coder**、擅长信息检索的 **Web Searcher**。在 1.5 时代，**ActorFactory** 获得了动态组装能力，可以根据 Planner 的指令，为 **Dynamic Actor** “装配”上最适合当前子任务的**工具（Tools）**和**知识（Knowledge）**，实现了从“固定专家”到“按需专家”的转变。

3. **记忆与知识（Context & Knowledge）**：为了在长时域任务中保持连贯性，Aime 构建了强大的**上下文（Context）**管理与**知识（Knowledge）**系统。**Context** 机制通过智能摘要与状态追踪，确保智能体在经历数百轮交互后依然“不忘初心”。而 **Knowledge** 系统则如同一个外置大脑，通过模板注入等方式，将领域最佳实践、操作规范等外部知识赋能给 **Planner** 和 **Actor**，提升决策质量与执行效率。

这三大支柱共同构成了一个能够应对复杂性、保持鲁棒性并持续演进的智能系统。

## 关键组件与核心机制
要深入理解 Aime 的工作原理，我们需要解构其内部的关键组件，并探究它们之间如何协作，共同实现从静态执行到动态演进的跨越。

### Planner 与 Execution Engine：规划与调度中枢
**Planner** 和 **Execution Engine** 共同构成了 Aime 的“大脑”与“神经中枢”，负责任务的分解、调度与监控。

- **Planner 的双重职责**：
	- **初始规划**：接收用户请求后，**Planner** 利用大语言模型（LLM）的理解与推理能力，将模糊的、高层次的目标分解为一系列结构化的、可执行的步骤（Actions）。
	- **动态重新规划（Replan）**：这是 Aime 1.5 演进的核心。**Planner** 会持续监控 **Execution Engine** 发回的执行状态。当出现以下情况时，**Replan** 机制被激活：
		- **执行失败**：某个 **Actor** 执行失败，**Planner** 需要分析失败原因，并决策是重试、切换方案，还是终止任务。
		- **意外发现**：**Actor** 在执行中获得了预料之外的“惊喜”，例如提前完成了后续多个步骤的目标。**Planner** 会识别这种情况，并动态调整计划，跳过已变得多余的步骤，从而提高效率。
		- **规划修正**：随着任务的深入，**Actor** 的执行结果可能暴露出初始规划的不足（如遗漏关键环节）。**Planner** 会基于新的信息，对后续计划进行增补或修正。

- **Execution Engine 的角色**：作为调度中心，**Execution Engine** 严格按照 **Planner** 的指令，有序地调用 **ActorFactory** 来创建并执行相应的 **Actor**。它不关心 **Actor** 的内部实现细节，只负责管理执行流程、记录中间状态与结果，并忠实地将这些信息反馈给 **Planner**。这种职责分离确保了规划层与执行层的解耦，使得整个系统更加清晰和易于维护。

### ActorFactory 与 Dynamic Actor：从固定专家到按需组装
**ActorFactory** 是 Aime 执行能力的核心来源，它体现了从 1.0 到 1.5 的关键转变。

- **Aime 1.0：专家注册与分发**：在早期版本中，**ActorFactory** 像一个“人才市场”，预先注册了一批拥有固定技能的专家 **Actor**，如 **Coder**、**Web Searcher** 和 **MCP Caller**（用于接入公司内部服务的执行器）。当 **Planner** 指定需要某种能力时，**ActorFactory** 便派遣对应的专家出场。这种模式的优点是能力可靠、行为可预测，但缺点是灵活性差，难以应对需要多种能力交叉的复合型任务。

- **Aime 1.5：动态能力的熔炉**：在 Aime 1.5 中，**ActorFactory** 演变成一个“动态能力熔炉”。它不再仅仅分发固定的专家，而是能够根据 **Planner** 针对当前特定子任务下发的“配方”，动态地创建一个 **Dynamic Actor**。这个“配方”明确了该 **Actor** 需要被赋予：
	- **角色（Role）**：定义其行为风格与核心使命，例如“一个精通 Go 语言的后端工程师”或“一个擅长数据分析与可视化的数据科学家”。
	- **工具集（Tools）**：从工具库中挑选并“装配”给 **Actor** 的具体能力，如文件读写、代码执行、数据库访问、API 调用等。
	- **知识片段（Knowledge）**：从知识库中检索并注入与当前任务高度相关的知识，如“本项目的代码规范”、“相关 API 的使用文档”或“数据可视化的最佳实践”。

通过这种方式，Aime 解决了“角色固化”的难题。例如，在构建一个需要前后端集成的“实时仪表盘”任务时，**ActorFactory** 可以动态生成一个同时掌握了代码编写、API 调用和前端框架知识的“全栈工程师” **Actor**，从而避免了前后端能力分离导致的集成鸿沟。

### 上下文管理与知识注入：实现记忆与智慧
长时域任务的成功执行，离不开对历史信息的有效记忆和对外部知识的灵活运用。

- **上下文的智能压缩与状态跟踪**：随着任务轮次的增加，完整的交互历史很快会超出 LLM 的上下文窗口限制。Aime 的**上下文（Context）**管理器采用了一种智能压缩机制，它并非简单地截断或生成通用摘要，而是利用 LLM 自身，根据预设的结构化提示，优先保留对任务至关重要的信息类别，如用户核心意图、关键决策点、代码变更历史、已确认的事实等。同时，系统会精确追踪每一步操作的状态，确保信息同步，并允许用户随时中断。这使得 Aime 即使在数百轮交互后，依然能保持对核心目标的记忆，有效解决了“迷失在中间（Lost in the middle）”的问题。

- **双层进展跟踪**：为了进一步增强长任务的稳定性，Aime 1.5 引入了**双层进展跟踪**机制。**Planner** 维护一个宏观的任务大纲（To-do List），而每个 **Dynamic Actor** 在执行自己的子任务时，也会维护一个微观的步骤清单。**Actor** 每完成一小步，就会更新自己的清单，并向 **Planner** 汇报。这种“双重记账”的方式，确保了智能体在宏观和微观层面都清楚“自己在哪”、“要去哪”，极大地降低了在复杂任务中迷失方向的风险。

- **知识库的场景化应用**：**知识（Knowledge）**系统是 Aime 超越 LLM 内生知识、确保专业性和可靠性的重要保障。知识以结构化的形式存储，并通过多阶段检索策略（精确匹配、多级过滤等）与当前任务场景适配。一旦匹配成功，相关知识便会通过**模板注入**的方式，整合到 **Planner** 或 **Actor** 的提示（Prompt）中，从而指导其规划与行动。这不仅能显著提升决策质量（例如，遵循特定的编码规范），还能通过提供可靠的外部事实，减少模型产生幻觉的风险。

## 架构的演进与优势
Aime 1.5 的动态演进架构，并非对 1.0 静态规划模式的简单替换，而是一次深刻的扬弃与整合。它旨在解决静态框架在开放环境中的三大结构性缺陷，从而赋予智能体更强的适应性、鲁棒性和问题解决能力。

### 攻克静态规划的三大困境
1. **从“僵化规划”到“自适应路径”**：
	- **困境**：Aime 1.0 的静态规划无法适应执行过程中的变化。即使在第一步就获得了最终数据，系统仍会机械地走完后续所有冗余的数据清洗和处理流程，造成资源浪费。
	- **解决方案**：Aime 1.5 的 **Dynamic Planner** 彻底改变了这一局面。它持续评估每一步的执行结果。当发现“捷径”时（如提前获取了干净数据），它会立即**重新规划（Replan）**，果断跳过后续不必要的步骤，将“局部优化”转化为“全局效率”的提升。

2. **从“固化角色”到“跨界融合”**：
	- **困境**：预定义的专家 **Actor** 难以处理需要跨领域能力的复合任务。例如，在构建实时仪表盘时，后端专家和前端专家“各自为政”，导致最终产物无法集成，核心的“实时交互”功能缺失。
	- **解决方案**：**ActorFactory** 的动态组装能力为此提供了完美答案。它可以根据任务需求，即时创造出一个融合了前后端技能的“全栈” **Dynamic Actor**。这个临时专家在一个统一的上下文中完成所有工作，自然地解决了能力交叉和集成的问题，确保最终产出是一个有机的整体，而非能力的碎片化拼凑。

3. **从“信息黑洞”到“单一事实来源”**：
	- **困境**：在多 **Actor** 协作中，信息在传递过程中会不断失真或缺失，如同“传话游戏”。一个 **Actor** 未能明确传递“数据不完整”的上下文，可能导致后续 **Actor** 基于错误假设进行分析，最终得出与事实相悖的结论。
	- **解决方案**：Aime 1.5 的架构通过共享的**上下文（Context）**和**双层进展跟踪**，努力构建一个“单一事实来源”。**Dynamic Actor** 在一个相对独立的、信息完备的环境中工作，减少了跨 **Actor** 的高频通信。当需要传递时，精细化的上下文管理机制会确保关键信息的完整性。这大大降低了因信息失真导致决策错误的风险。

### 统一架构的核心优势
通过融合规划的稳定性与演进的灵活性，Aime 的统一架构展现出几大核心优势：

- **鲁棒性与错误恢复**：将复杂任务分解为由 **Dynamic Actor** 执行的、更内聚的子任务，天然提升了系统的鲁棒性。单个 **Actor** 的失败不再轻易导致整个任务链的崩溃。**Execution Engine** 捕获错误后，**Planner** 可以灵活决策，或调整参数重试，或切换到备用方案，实现了强大的容错能力。

- **可扩展性与专业化**：**ActorFactory** 的设计使得系统扩展变得简单而高效。开发者可以专注于定义新的工具或知识，然后通过“配方”将其赋能给 **Dynamic Actor**，而无需改动核心的规划与调度逻辑。这使得 Aime 既能保持框架的通用性，又能快速深入任何专业领域。

- **知识驱动的可靠性**：通过外部**知识库（Knowledge）**的引入，Aime 的决策不再仅仅依赖于 LLM 内部可能存在偏差或幻觉的参数化知识。领域最佳实践、操作规范等被显式地注入执行过程，这不仅提升了结果的质量和一致性，也使其行为更加可解释、可信赖。

- **面向真实业务的实现抓手**：无论是 **Coder** 在代码开发中对工作区（Workspace）的感知，**Web Searcher** 在浏览器交互中对视觉与文本信息的综合利用，还是 **MCP Caller** 对公司内部各类平台的工具化封装，Aime 的架构始终强调与真实业务场景的深度结合，为解决工程、检索、交互等实际问题提供了具体的落地路径。

## 实战检验与评测
一个架构的优劣，最终需要通过在真实且具挑战性的任务上的表现来检验。Aime 1.5 的动态演进框架在多个公认的、领域差异显著的基准测试中，验证了其设计的有效性。

### 跨领域基准测试表现
为了全面评估其通用问题解决能力，Aime 1.5 在采用相同基座模型的前提下，参与了三大基准测试：

- **GAIA (General AI Assistants)**：专注于评估智能体在处理需要长链逻辑推理、多步骤、跨领域问题时的规划与纠错能力。Aime 在此测试中取得了领先成绩，尤其是在高难度问题上的表现，这很大程度上归功于 **Dynamic Planner** 的动态调整与重新规划能力。面对复杂的推理链，当一条路径被证明无效时，系统能够及时止损并探索新的可能性，从而显著提升了任务的最终成功率。

- **SWE-bench Verified**：专注于评估在真实、复杂的开源项目代码库中进行精准 Bug 修复的能力。Aime 在此基准上的有效性，得益于 **ActorFactory** 的按需生成机制。它能够根据 Bug 的具体情况，即时生成并配置最合适的“代码分析师”或“调试工程师” **Actor**，这种“按需组装”的灵活性，相比固定的单一角色智能体，能更好地匹配复杂软件工程任务的需求。

- **WebVoyager**：专注于评估智能体在真实、不可预测的互联网环境中自主完成多步交互任务的能力。Aime 在此测试中的鲁棒性，源于其高效的“感知-决策”反馈闭环。通过 **Dynamic Actor** 的主动状态汇报与 **Dynamic Planner** 的快速响应，系统能够从常见的页面变化或执行错误中迅速恢复，并根据新情况调整策略，从而在多变的动态环境中保持较高的任务成功率。

### 结论概述
在上述三个差异巨大的专业领域中，Aime 1.5 的通用框架均取得了极具竞争力的结果，其表现甚至超过了某些为特定任务专门设计的智能体系统。这一系列实证结果有力地支持了 Aime 1.5 的核心设计哲学：**一个设计良好的通用框架，凭借其内在的自适应性与动态调整机制，能够在高度专业的领域中达到甚至超过专用系统的性能。** 它证明了，从“有序”迈向“演进”，是构建下一代强大AI智能体的必由之路。

## 结论与展望
Aime 架构的探索，是从构建一个“听话的执行者”到培育一个“智慧的问题解决者”的深刻转变。通过将 **PlanAct** 的结构化规划与**动态演进**的自适应能力相结合，Aime 形成了一个既稳定又灵活的统一框架。**Dynamic Planner** 与 **Dynamic Actor** 的引入，有效克服了传统静态智能体在面对真实世界不确定性时所暴露的僵化、固化和信息失真等结构性缺陷。

在 **GAIA**、**SWE-bench** 和 **WebVoyager** 等多个基准测试中的出色表现，初步验证了这一混合式架构的有效性与通用性。它证明了，一个具备强大自适应能力的通用框架，有潜力在多个专业领域中取得卓越成就。这不仅是 Aime 项目的一次成功实践，也为复杂智能体的设计提供了有价值的参考。

当然，探索永无止境。Aime 的演进之路仍在继续。未来的工作将聚焦于进一步提升执行效率，通过更高效的规划策略与成本感知机制，降低灵活性带来的计算开销；同时，我们也将致力于增强结果的稳定性，通过系统性地沉淀与泛化成功的执行经验，构建一个能够自我学习、越用越聪明的智能系统。我们相信，这条从有序到演进的道路，将引领我们走向更通用、更强大的未来智能。


</content>
